{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lhiaq5kIBkPA"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbKYBPDcBkPC",
    "outputId": "af561028-853e-4bff-efb5-5c4cfc0c37d4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import Model, Input, optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout, GRU, concatenate\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODhkRv5tBkPD"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61M-abDRBkPE",
    "outputId": "c9183c0b-caa2-474b-f054-ee41ae2999dc"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'data_extracted.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-iCzLoZBkPE"
   },
   "source": [
    "### Text and Numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TnjdUTvsBkPE",
    "outputId": "998e5892-c1e3-4c45-90c9-8ad4ba810c76"
   },
   "outputs": [],
   "source": [
    "text_input = df[\"TEXT\"].values\n",
    "numeric_input = df[[\"NUMBER_OF_PROCEDURES\", \"NUMBER_OF_DIAGNOSIS\",\\\n",
    "                    \"ICU_LOS\", \"MARRIED\", \"DIVORCED\", \"SINGLE\", \"SEPARATED\",\\\n",
    "                    \"WIDOWED\", \"UNKNOWN (DEFAULT)\",\"LIFE PARTNER\"]]\n",
    "print(text_input[0])\n",
    "numeric_input.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8vNKnGlBkPF"
   },
   "source": [
    "### Tokenize the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H26X-2J-BkPF",
    "outputId": "bd9937ea-2221-484e-813e-4457f4e30611"
   },
   "outputs": [],
   "source": [
    "max_sequence = 300\n",
    "max_words = 50000\n",
    "X = text_input\n",
    "tokenizer = Tokenizer(num_words = max_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower = True)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X, maxlen = max_sequence)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgLWNkLyBkPF"
   },
   "source": [
    "### Input and Output Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xz4a0bRaBkPG",
    "outputId": "26117284-2a08-49a7-88b7-8e625ddfb136"
   },
   "outputs": [],
   "source": [
    "x = X                 # text input   (  , 250)                    \n",
    "z = numeric_input.values     # numeric inpute(  , 10)\n",
    "y = df[\"LENGTH_OF_STAY\"].values\n",
    "\n",
    "print(x.shape,y.shape,z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGtdm2zTBkPG"
   },
   "source": [
    "### Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V99W8TSABkPG",
    "outputId": "02cd7991-e2f6-4d67-84ee-9697ee1113df"
   },
   "outputs": [],
   "source": [
    "print('Output (Length of stay):\\n','Mean : {}, Median : {}, Max : {}, Min : {}, Range: {}'\\\n",
    "      .format(np.mean(y), np.median(y), np.max(y), np.min(y), np.max(y) - np.min(y)), '\\n')\n",
    "for i in range(z.shape[1]):\n",
    "    print('{}:'.format(numeric_input.columns[i]))\n",
    "    print('Mean : {}, Median : {}, Max : {}, Min : {}, Range: {}'\\\n",
    "          .format(np.mean(z[:,i]), np.median(z[:,i]), np.max(z[:,i]), np.min(z[:,i]), \\\n",
    "                  np.max(z[:,i]) - np.min(z[:,i])), '\\n')\n",
    "plt.subplot(1,3,1)\n",
    "plt.scatter(range(len(y)), y, s= 1, color = 'g', label = 'scatter')\n",
    "plt.hlines(y = np.mean(y), xmin = 0, xmax = len(y), colors = 'b', label = 'mean')\n",
    "plt.title('Output : scatter plot & mean'), plt.legend(loc = 1)\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(y, bins = 6, label = 'hist')\n",
    "plt.vlines(x = np.mean(y), ymin = 0, ymax = len(y), colors = 'g', label = 'mean')\n",
    "plt.title('Output : histogram & mean'), plt.legend(loc = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caTvXXEmBkPG"
   },
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRLpYn_iBkPH",
    "outputId": "80e7ce16-f16a-414e-dbc5-eade170bc423"
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "x_train, x_test, z_train, z_test, y_train, y_test = train_test_split(x,z,y, test_size = test_size, random_state = 0)\n",
    "print('\\nNumber of training data:',x_train.shape[0])\n",
    "print('\\nNumber of text data:',x_test.shape[0])\n",
    "z_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HBUxK49BkPH"
   },
   "source": [
    "### Model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUs-5pjlBkPH"
   },
   "source": [
    "#### Linear Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahVoci5tBkPH",
    "outputId": "0f49591e-631b-466f-a472-859a93b53e14"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "yhat_cv = cross_val_predict(lr, z_train, y_train, cv = 4)\n",
    "yhat_cv_text = cross_val_predict(lr, x_train, y_train, cv = 4)\n",
    "\n",
    "score_cv = cross_val_score(lr, z_train, y_train, cv = 4)\n",
    "score_cv_text = cross_val_score(lr, x_train, y_train, cv = 4)\n",
    "\n",
    "R2 = r2_score(y_train, yhat_cv)\n",
    "MSE = mean_squared_error(y_train, yhat_cv)\n",
    "MSE_text = mean_squared_error(y_train, yhat_cv_text)\n",
    "\n",
    "lr.fit(z_train, y_train)\n",
    "yhat_train = lr.predict(z_train)\n",
    "score_train = lr.score(z_train, y_train)\n",
    "print('\\nLinear regression training score (R squared) of numeric data ( , 10) is',score_train)\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "yhat_train_text = lr.predict(x_train)\n",
    "score_train_text = lr.score(x_train, y_train)\n",
    "print('\\nLinear regression training score (R squared) of text data ( , 250) is', score_train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(degree = 2)\n",
    "z_train_poly = pf.fit_transform(z_train)\n",
    "z_test_poly = pf.fit_transform(z_test)\n",
    "\n",
    "x_train_poly = pf.fit_transform(x_train)\n",
    "x_test_poly = pf.fit_transform(x_test)\n",
    "\n",
    "poly_num = LinearRegression()\n",
    "poly_num.fit(z_train_poly, y_train)\n",
    "yhat_poly_num = poly_num.predict(z_train_poly)\n",
    "\n",
    "poly_text = LinearRegression()\n",
    "poly_text.fit(x_train_poly, y_train)\n",
    "yhat_poly_text = poly_text.predict(x_train_poly)\n",
    "\n",
    "print('Numeric:')\n",
    "print('\\nNumeric: R squared error for polynomial regression is:',poly_num.score(z_train_poly, y_train))\n",
    "print('Actual output:', y_train[:5])\n",
    "print('\\nPredicted output:', yhat_poly_num[:5])\n",
    "print('\\nText:')\n",
    "print('\\nR squared error for polynomial regression is:',poly_text.score(x_train_poly, y_train))\n",
    "print('Actual output:', y_train[:5])\n",
    "print('\\nPredicted output:', yhat_poly_text[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07G910v5BkPI"
   },
   "source": [
    "#### DNN : Numeric data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7e2eeZGRBkPI",
    "outputId": "c5569e8e-b7fd-41b5-9c10-74474929abd7"
   },
   "outputs": [],
   "source": [
    "m_num = Sequential() \n",
    "num_input = Input(shape = (10, ))\n",
    "numl = Dense(512, activation = 'linear')(num_input)\n",
    "d1 = Dropout(0.2)(numl)\n",
    "numl2 = Dense(256, activation = 'relu')(d1)\n",
    "d2 = Dropout(0.2)(numl2)\n",
    "numl3 = Dense(128, activation = 'relu')(d2)\n",
    "d3 = Dropout(0.2)(numl3)\n",
    "numl4 = Dense(64, activation = 'relu')(d3)\n",
    "d4 = Dropout(0.2)(numl4)\n",
    "output = Dense(1, activation = \"linear\")(d4)\n",
    "m_num = Model(inputs = num_input, outputs = output)\n",
    "m_num.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBegF1HbBkPI",
    "outputId": "4b4eb8a3-8eab-4d93-aa00-458c8d86c7fa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "adam = optimizers.Adam(lr = 0.00001)\n",
    "m_num.compile(optimizer = adam, loss = 'mae', metrics=['mse', 'mae'])\n",
    "\n",
    "'''fit the model with 20% validation'''\n",
    "m_num_history = m_num.fit(z_train, y_train, batch_size=100, epochs=10, validation_split = 0.2, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNPwNss7BkPI",
    "outputId": "961e3a3f-10cc-4eec-8d93-f8cfd39b8b60"
   },
   "outputs": [],
   "source": [
    "yhat_train_num = m_num.predict(z_train)\n",
    "yhat_test_num = m_num.predict(z_test)\n",
    "plt.scatter(z_train[:,1], y_train, s = 5 , color = 'g', label = 'actual')\n",
    "plt.scatter(z_train[:,1], yhat_train_num, s=5, color = 'b', label ='predicted')\n",
    "plt.legend(loc = 1)\n",
    "print('\\nRsquared score on train is:',r2_score(y_train, yhat_train_num))\n",
    "print('\\nRsquared score on test is:',r2_score(y_test, yhat_test_num))\n",
    "print('\\nActual output:\\n', y_train[:5])\n",
    "print('\\nPredicted output:\\n', yhat_train_num[:5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWOuabrDBkPI",
    "outputId": "14a47945-5057-4d27-d174-2961ff03369c"
   },
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.plot(range(len(m_num_history.history['val_loss'])),m_num_history.history['val_loss'],'-o', label = 'val_loss')\n",
    "plt.plot(range(len(m_num_history.history['loss'])),m_num_history.history['loss'],'-o', label = 'train_loss')\n",
    "plt.legend(loc = 1, fontsize = 10)\n",
    "plt.ylabel('MSE'), plt.title('DNN: Numeric data')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(range(len(m_num_history.history['val_mae'])),m_num_history.history['val_mae'],'-o', label = 'validation MAE')\n",
    "plt.plot(range(len(m_num_history.history['mae'])),m_num_history.history['mae'],'-o', label = 'train MAE')\n",
    "plt.legend(loc = 1, fontsize = 10)\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiddwOfYBkPJ"
   },
   "source": [
    "#### DNN : Text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEJC5PSaBkPJ",
    "outputId": "07f1bf0d-a9ec-4b12-9a4e-90ed6e90555c"
   },
   "outputs": [],
   "source": [
    "m_text = Sequential() \n",
    "text_input = Input(shape = (300, ))\n",
    "numl = Dense(1000, activation = 'softmax')(text_input)\n",
    "d1 = Dropout(0.4)(numl)\n",
    "numl2 = Dense(500, activation = 'relu')(d1)\n",
    "d2 = Dropout(0.4)(numl2)\n",
    "numl3 = Dense(100, activation = 'relu')(d2)\n",
    "d3 = Dropout(0.3)(numl3)\n",
    "output = Dense(1, activation = \"linear\")(d3)\n",
    "m_text = Model(inputs = text_input, outputs = output)\n",
    "# m_text.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9iB56frBkPK",
    "outputId": "6f4ab41b-343b-4e6f-f528-ee9d95ca34a9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "adam = optimizers.Adam(lr = 0.1)\n",
    "m_text.compile(optimizer = adam, loss = 'mse', metrics=['mse', 'mae'])\n",
    "\n",
    "'''fit the model with 20% validation'''\n",
    "m_text_history = m_text.fit(x_train, y_train, batch_size=100, epochs=100, validation_split = 0.2, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yesxeMllBkPK",
    "outputId": "b87732f3-2119-41a1-f1f9-86cf0b54cb81",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yhat_train_text = m_text.predict(x_train)\n",
    "yhat_test_text = m_text.predict(x_test)\n",
    "plt.scatter(range(len(y_train)), y_train, s = 5 , color = 'g', label = 'actual')\n",
    "plt.scatter(range(len(y_train)), yhat_train_text, s=5, color = 'b', label ='predicted')\n",
    "plt.legend(loc = 1)\n",
    "print('\\nRsquared score on train is:',r2_score(y_train, yhat_train_text))\n",
    "print('\\nRsquared score on test is:',r2_score(y_test, yhat_test_text))\n",
    "print('\\nActual output:\\n', y_train[:5])\n",
    "print('\\nPredicted output:\\n', yhat_train_text[:5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4qfRUZhBkPK",
    "outputId": "b3c48cd5-b919-41e3-f6ca-4ffab67e402e"
   },
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.plot(range(len(m_text_history.history['val_loss'])),m_text_history.history['val_loss'],'-o', label = 'val_loss')\n",
    "plt.plot(range(len(m_text_history.history['loss'])),m_text_history.history['loss'],'-o', label = 'train_loss')\n",
    "plt.legend(loc = 1, fontsize = 10)\n",
    "plt.ylabel('MSE'), plt.title('DNN: Text data')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(range(len(m_text_history.history['val_mae'])),m_text_history.history['val_mae'],'-o', label = 'validation MAE')\n",
    "plt.plot(range(len(m_text_history.history['mae'])),m_text_history.history['mae'],'-o', label = 'train MAE')\n",
    "plt.legend(loc = 1, fontsize = 10)\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7duc52noBkPK"
   },
   "source": [
    "#### RNN : Text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34Ep68kjBkPK",
    "outputId": "826a98f1-2b99-4b56-d103-74b0dae36128"
   },
   "outputs": [],
   "source": [
    "embedding_size = 250\n",
    "\n",
    "nlp_input = Input(shape=(max_sequence,))\n",
    "emb = Embedding(max_words, embedding_size, input_length = max_sequence)(nlp_input)  # text input layer\n",
    "l1 = Dense(100, activation = 'elu')(emb)\n",
    "nl2 = LSTM(100, activation = 'relu', kernel_initializer = 'glorot_uniform', return_sequences=True)(l1)\n",
    "d1 = Dropout(0.2)(nl2)\n",
    "nl3 = LSTM(50, activation = 'relu', kernel_initializer = 'glorot_uniform', return_sequences=True)(d1)\n",
    "d2 = Dropout(0.2)(nl3)\n",
    "nl4 = LSTM(50, activation = 'tanh', dropout = 0.2, recurrent_dropout = 0.15, return_sequences = True)(d2)\n",
    "nl5 = GRU(50, activation = 'relu', recurrent_activation = 'tanh')(nl4)\n",
    "\n",
    "output = Dense(1, activation = \"linear\")(nl5)\n",
    "\n",
    "rnn_text = Model(inputs = [nlp_input], outputs = [output])\n",
    "rnn_text.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8KW4mXUHBkPL",
    "outputId": "165239ed-7227-45ed-abb0-b652a90b04fe"
   },
   "outputs": [],
   "source": [
    "solver = optimizers.Adam(learning_rate = 1)\n",
    "callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "rnn_text.compile(optimizer = solver,loss = 'mse', metrics = ['mae','mse'])\n",
    "rnn_text_history = rnn_text.fit(x_train, y_train, batch_size = 100, epochs = 1, validation_split = 0.2, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDj-KDo8BkPL",
    "outputId": "0a5a5325-d319-4714-ed48-5ae5247e0d94"
   },
   "outputs": [],
   "source": [
    "yhat_train_rnn_text = rnn_text.predict(x_train)\n",
    "yhat_test_rnn_text = rnn_text.predict(x_test)\n",
    "plt.scatter(x_train[:,1], y_train, s = 5 , color = 'g', label = 'actual')\n",
    "plt.scatter(x_train[:,1], yhat_train_rnn_text, s=5, color = 'b', label ='predicted')\n",
    "plt.legend(loc = 1)\n",
    "print('\\nRsquared score on train is:',r2_score(y_train, yhat_train_rnn_text))\n",
    "print('\\nRsquared score on test is:',r2_score(y_test, yhat_test_rnn_text))\n",
    "print('\\nActual output:\\n', y_train[:5])\n",
    "print('\\nPredicted output:\\n', yhat_train_rnn_text[:5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pmw4jyyQBkPL",
    "outputId": "c4583c06-2f9a-4a74-c485-bee3eb19e1e8"
   },
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.plot(range(len(rnn_text_history.history['val_loss'])),rnn_text_history.history['val_loss'],'-o', label = 'val_loss')\n",
    "plt.plot(range(len(rnn_text_history.history['loss'])),rnn_text_history.history['loss'],'-o', label = 'train_loss')\n",
    "plt.legend(loc = 1, fontsize = 10)\n",
    "plt.ylabel('MSE'), plt.title('RNN : Text data')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(range(len(rnn_text_history.history['val_mae'])),rnn_text_history.history['val_mae'],'-o', label = 'validation MAE')\n",
    "plt.plot(range(len(rnn_text_history.history['mae'])),rnn_text_history.history['mae'],'-o', label = 'train MAE')\n",
    "plt.legend(loc = 1, fontsize = 10)\n",
    "plt.ylabel('MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ua0GeW9yBkPM"
   },
   "source": [
    "#### RNN : Text & DNN : Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-DP-Mc9BkPM",
    "outputId": "d976f3e9-9560-4c66-df01-ecf8f04c0c4c"
   },
   "outputs": [],
   "source": [
    "embedding_size = 100\n",
    "\n",
    "'''Sequential model'''\n",
    "m = Sequential() \n",
    "\n",
    "'''Numeric input layer'''\n",
    "num_input = Input(shape = (10, ))\n",
    "numl = Dense(100, activation = 'relu')(num_input)\n",
    "dl = Dropout(0.2)(numl)\n",
    "\n",
    "'''Text input layer'''\n",
    "nlp_input = Input(shape=(max_sequence,))\n",
    "emb = Embedding(max_words, embedding_size, input_length = max_sequence)(nlp_input)  # text input layer\n",
    "nl2 = LSTM(200, activation = 'tanh', kernel_initializer = 'glorot_uniform', return_sequences=True)(emb)\n",
    "d1 = Dropout(0.2)(nl2)\n",
    "nl3 = LSTM(100, activation = 'tanh', kernel_initializer = 'glorot_uniform', return_sequences=True)(d1)\n",
    "d2 = Dropout(0.2)(nl3)\n",
    "nl4 = LSTM(50, activation = 'tanh', dropout = 0.2, recurrent_dropout = 0.2, return_sequences = True)(d2)\n",
    "nl5 = GRU(50, activation = 'tanh', recurrent_activation = 'tanh')(nl4)\n",
    "\n",
    "merge = concatenate([dl, nl5])   # merge Dense and LSTM layers\n",
    "\n",
    "output = Dense(1, activation = \"linear\")(merge)\n",
    "\n",
    "m = Model(inputs = [num_input, nlp_input], outputs = [output])\n",
    "\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8Q3wVLRBkPM"
   },
   "outputs": [],
   "source": [
    "solver = optimizers.Adam(learning_rate = 1)\n",
    "callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "m.compile(optimizer = solver,loss = 'mae', metrics = ['mae','mse'])\n",
    "history = m.fit([z_train, x_train], y_train, batch_size = 100, epochs = 1, validation_split = 0.2, callbacks = [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ui7F5ZfNBkPN"
   },
   "outputs": [],
   "source": [
    "yhat_train = m.predict([z_train, x_train])\n",
    "yhat_test = m.predict([z_test, x_test])\n",
    "print('Rsquared score on train is:',r2_score(y_train, yhat_train))\n",
    "print('Rsquared score on test is:',r2_score(y_test, yhat_test))\n",
    "plt.scatter(z_train[:,1], y_train, s = 5 , color = 'g', label = 'actual')\n",
    "plt.scatter(z_train[:,1], yhat_train, s=5, color = 'b', label ='predicted')\n",
    "plt.legend(loc = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kTvrYBwBkPN"
   },
   "outputs": [],
   "source": [
    "Weights = []\n",
    "for layer in m.layers:\n",
    "    Weights.append({layer : layer.get_weights()})\n",
    "Weights"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
